{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "lo8i8SaHqaIe"
   },
   "outputs": [],
   "source": [
    "# Start by importing the necessary libraries\n",
    "import nltk\n",
    "import string\n",
    "from nltk.util import ngrams\n",
    "from nltk.probability import FreqDist\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /mnt/sandbox/ComputationalLinguistics/CL/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /mnt/sandbox/ComputationalLinguistics/CL/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /mnt/sandbox/ComputationalLinguistics/CL/lib/python3.10/site-packages (from nltk) (1.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /mnt/sandbox/ComputationalLinguistics/CL/lib/python3.10/site-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /mnt/sandbox/ComputationalLinguistics/CL/lib/python3.10/site-packages (from nltk) (4.65.0)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.25.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-1.25.0\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7kBr3pLmryq8",
    "outputId": "bd9b60d4-69d9-4bda-eb5b-4d54565d4e7d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /home/lisa/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/lisa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the reuters corpus is downloaded\n",
    "nltk.download('reuters')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "4zJsZVNxrz5q"
   },
   "outputs": [],
   "source": [
    "# Load the reuters corpus\n",
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "N4cZQTxtsByK"
   },
   "outputs": [],
   "source": [
    "#type(reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(reuters.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reuters.readme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reuters.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(corpus):\n",
    "    \"\"\"\n",
    "    Preprocess the raw text of a corpus. Namely remove numbers, lowercase, remove puncutation, tokenize.\n",
    "    Parameters:\n",
    "        corpus (str): the corpus of text to be preprocessed\n",
    "    Returns:\n",
    "        corpus (list): the preprocessed corpus\n",
    "    \"\"\"\n",
    "    # remove numbers\n",
    "    corpus = re.sub(r'\\d+', ' ', corpus)\n",
    "    # lowercase everything\n",
    "    corpus = corpus.lower() \n",
    "    # remove punctuation \n",
    "    corpus = \"\".join([char for char in corpus if char not in string.punctuation])\n",
    "    # tokenize \n",
    "    corpus = nltk.word_tokenize(corpus)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# .raw() to extract text from corpus \n",
    "print(type(reuters.raw()))\n",
    "prep_reuters = preprocessing(reuters.raw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asian', 'exporters', 'fear', 'damage', 'from', 'usjapan', 'rift', 'mounting', 'trade', 'friction', 'between', 'the', 'us', 'and', 'japan', 'has', 'raised', 'fears', 'among', 'many', 'of', 'asias', 'exporting', 'nations', 'that', 'the', 'row', 'could', 'inflict', 'farreaching']\n"
     ]
    }
   ],
   "source": [
    "print(prep_reuters[:30])\n",
    "# usjapan from u.s.-japan ???????????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. NGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(corpus, n:int):\n",
    "    \"\"\"\n",
    "    Creates ngrams of a preprocessed corpus.\n",
    "    Parameters:\n",
    "        corpus (list): a preprocessed (lowercase, no punctuation, no numbers, tokenized) corpus\n",
    "        n (int): the length of each ngram\n",
    "    Returns:\n",
    "        ngrams (zip): the ngrams of the corpus\n",
    "    \"\"\"\n",
    "    ngrams = nltk.ngrams(corpus, n) \n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_ngrams(ngrams):\n",
    "    \"\"\"\n",
    "    Calculates the frequency of each ngram and displays them. ???????????????????????????\n",
    "    Parameters:\n",
    "        ngrams (zip): the ngrams to count the frequencies of\n",
    "    Returns: \n",
    "        freq_ngrams (FreqDist): each ngram and its frequency\n",
    "    \"\"\"\n",
    "    freq_ngrams = nltk.FreqDist(ngrams)\n",
    "    # display not showing, however showing if called afterwards?????????????????????\n",
    "    # print(freq_ngrams.items()) \n",
    "    # print(freq_ngrams) \n",
    "    # @ToDO: display ngrams!!!!!!!!!!!\n",
    "    return freq_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'zip'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({('mln', 'vs', 'mln'): 3402, ('cts', 'vs', 'cts'): 1779, ('revs', 'mln', 'vs'): 1515, ('shr', 'cts', 'vs'): 1446, ('the', 'company', 'said'): 1180, ('vs', 'cts', 'net'): 1169, ('cts', 'net', 'vs'): 1082, ('of', 'mln', 'dlrs'): 1049, ('net', 'vs', 'revs'): 887, ('mln', 'dlrs', 'in'): 819, ...})"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_reuters = ngrams(prep_reuters, 3)\n",
    "print(type(ngrams_reuters))\n",
    "\n",
    "freq_ngrams_reuters = freq_ngrams(ngrams_reuters)\n",
    "freq_ngrams_reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[(('automotive', 'technologies', 'corp'), 1), (('technologies', 'corp', 'year'), 1)]\n",
      "[('automotive', 'technologies', 'corp'), ('technologies', 'corp', 'year')]\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gestresstes', 'panterleun']"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(list(freq_ngrams_reuters.items())[-3:]))\n",
    "print(list(freq_ngrams_reuters.items())[-3+1:])\n",
    "print(list(freq_ngrams_reuters)[-3+1:])\n",
    "position = np.argmax([i[1] for i in list(freq_ngrams_reuters.items())[-3+1:]])\n",
    "print(position)\n",
    "#tuppel = (1,2)\n",
    "#tuppel[1]\n",
    "preprocessing('hi du 55 gestresstes panterleun')[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive_text_model(input_sentence, freq_ngrams): \n",
    "    \"\"\"\n",
    "    Predict the next word of an input sentence. \n",
    "    Parameters:\n",
    "        input_sentence (string): the sentence to predict a new word for\n",
    "        freq_ngrams (FreqDist): the ngrams and their frequencies to base the prediction on\n",
    "    Returns:\n",
    "        next_word (string): the next word or a no-next-word message\n",
    "    \"\"\"\n",
    "    # preprocess input sequence\n",
    "    prep_input_sentence = preprocessing(input_sentence) \n",
    "    # change type of the freq_ngrams class object to list\n",
    "    freq_ngrams = list(freq_ngrams.items())\n",
    "    # extract the last n-1 words from the sentence, \n",
    "    # where n is the length of the ngrams\n",
    "    len_ngrams = len(freq_ngrams[0][0])\n",
    "    last_n_words = prep_input_sentence[-len_ngrams+1:]\n",
    "    # collect all possible next words and their frequencies in a list\n",
    "    possible_next_words = []\n",
    "    for ngram in freq_ngrams:\n",
    "        i = 0\n",
    "        for word in last_n_words: \n",
    "            if ngram[0][i] == word:\n",
    "                i += 1\n",
    "                if i == len_ngrams-1:\n",
    "                    possible_next_words.append(ngram)\n",
    "            else:\n",
    "                break\n",
    "    # choose the next word according to the highest frequency\n",
    "    # make sure there is at least one possible word\n",
    "    if possible_next_words == []:\n",
    "        next_word = 'No next word based on this corpus'\n",
    "    else: \n",
    "        position = np.argmax([i[1] for i in possible_next_words])\n",
    "        next_word = possible_next_words[position][0][len_ngrams-1]\n",
    "    \n",
    "    return next_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = 'hi du 55 gestresstes panterleun automotive technologies of the ' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'company'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictive_text_model(input_sentence, freq_ngrams_reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
